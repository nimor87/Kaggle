{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Analytics Customer Revenue Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzis of a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to predict revenue per customer. \n",
    "\n",
    "Link to Data: https://www.kaggle.com/c/ga-customer-revenue-prediction/data\n",
    "\n",
    "We are predicting the natural log of the sum of all transactions per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "def load_df(csv_path='train.csv', nrows=None):\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    \n",
    "    df = pd.read_csv(csv_path, \n",
    "                     converters={column: json.loads for column in JSON_COLUMNS}, \n",
    "                     dtype={'fullVisitorId': 'str'}, # Important!!\n",
    "                     nrows=nrows)\n",
    "    \n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = load_df()\n",
    "df_test = load_df('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom function to extract more information from dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_time(POSIX):\n",
    "    \n",
    "    year = int(time.strftime('%Y', time.localtime(POSIX)))\n",
    "    month = int(time.strftime('%m', time.localtime(POSIX)))\n",
    "    day = int(time.strftime('%d', time.localtime(POSIX)))\n",
    "    hour = int(time.strftime('%H', time.localtime(POSIX)))\n",
    "    \n",
    "    dayofweek = int(time.strftime('%w', time.localtime(POSIX)))\n",
    "    dayofyear = int(time.strftime('%j', time.localtime(POSIX)))\n",
    "    weekofyear = int(time.strftime('%W', time.localtime(POSIX)))\n",
    "    \n",
    "    Is_month_start = True if day < 5 else False\n",
    "    Is_month_end = True if day > 25 else False\n",
    "    Is_quarter_start = True if month in [1, 4, 7, 10] and day < 15 else False \n",
    "    Is_quarter_end = True if month in [3, 6, 9, 12] and day > 15 else False\n",
    "    Is_year_start = True if dayofyear < 50 else False\n",
    "    Is_year_end = True if dayofyear > 300 else False\n",
    "    \n",
    "    return [year, month, day, hour, dayofweek, dayofyear, weekofyear, Is_month_start, Is_month_end, Is_quarter_start, Is_quarter_end, Is_year_start, Is_year_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_columns = ['year', 'month', 'day', 'hour', 'dayofweek', 'dayofyear', 'weekofyear', 'Is_month_start', 'Is_month_end', 'Is_quarter_start', 'Is_quarter_end', 'Is_year_start', 'Is_year_end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_time_columns(df):\n",
    "    visitStartTime = df.visitStartTime\n",
    "    custom_times = list()\n",
    "    for starttime in visitStartTime:\n",
    "        custom_times.append(custom_time(starttime))\n",
    "    df_time = pd.DataFrame(custom_times, columns=time_columns)\n",
    "    df_time = pd.concat([df, df_time], axis=1)\n",
    "    df_time.drop('visitStartTime', axis=1, inplace=True)\n",
    "    return df_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = custom_time_columns(df_train)\n",
    "df_test = custom_time_columns(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns contain only one unique value and are not useful for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "const_cols = [c for c in df_train.columns if df_train[c].nunique(dropna=False)==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_time.drop(const_cols, axis=1, inplace=True)\n",
    "df_test_time.drop(const_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing some columns that don't contain any useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_time.drop(['sessionId','visitId','date','trafficSource.campaignCode'],axis=1,inplace=True)\n",
    "df_test_time.drop(['sessionId','visitId','date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_cols = [col for col in df_train_time.columns if (df_train_time[col].dtype == 'object' and col not in ['fullVisitorId', 'totals.transactionRevenue'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in cat_cols:\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(df_train_time[col].values.astype('str')) + list(df_test_time[col].values.astype('str')))\n",
    "    df_train_time[col] = lbl.transform(list(df_train_time[col].values.astype('str')))\n",
    "    df_test_time[col] = lbl.transform(list(df_test_time[col].values.astype('str')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bool_cols = [col for col in df_train_time.columns if df_train_time[col].dtype == 'bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in bool_cols:\n",
    "    df_train_time[col] = df_train_time[col].astype(float)\n",
    "    df_test_time[col] = df_test_time[col].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling missing values with zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_time.fillna(0, inplace=True)\n",
    "df_test_time.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_time.set_index('fullVisitorId', inplace=True)\n",
    "df_test_time.set_index('fullVisitorId', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating training set and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features = [c for c in df_train_time.columns]\n",
    "features.remove(\"totals.transactionRevenue\")\n",
    "df_train_time[\"totals.transactionRevenue\"] = np.log1p(df_train_time[\"totals.transactionRevenue\"].astype(float))\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(df_train_time[features], df_train_time[\"totals.transactionRevenue\"], test_size=0.25, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb \n",
    "\n",
    "params = {\"objective\" : \"regression\", \"metric\" : \"rmse\",\n",
    "              \"num_leaves\" : 50, \"learning_rate\" : 0.02, \n",
    "              \"bagging_fraction\" : 0.75, \"feature_fraction\" : 0.8, \"bagging_frequency\" : 9}\n",
    "    \n",
    "lgb_train = lgb.Dataset(train_x, label=train_y)\n",
    "lgb_val = lgb.Dataset(valid_x, label=valid_y)\n",
    "model = lgb.train(params, lgb_train, 1000, valid_sets=[lgb_val], early_stopping_rounds=150, verbose_eval=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(df_test_time[features], num_iteration=model.best_iteration)\n",
    "preds[preds < 0] = 0\n",
    "df_test_time[\"PredictedLogRevenue\"] = np.expm1(preds)\n",
    "submission = df_test_time.groupby(\"fullVisitorId\").agg({\"PredictedLogRevenue\" : \"sum\"}).reset_index()\n",
    "submission[\"PredictedLogRevenue\"] = np.log1p(submission[\"PredictedLogRevenue\"])\n",
    "submission.to_csv(\"baseline.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
